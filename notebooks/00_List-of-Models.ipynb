{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WhatsApp Message Classifier & Extractor ‚Äì Model Options\n",
    "\n",
    "This document summarizes all models and tools one can use to build an Automated WhatsApp Message Classifier and Information Extractor for SMB workflows.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Pretrained Classifiers (Zero-Shot, No Training Needed)\n",
    "\n",
    "| Model Name | Source | Tasks | Free? | Pros | Cons |\n",
    "|------------|--------|-------|-------|------|------|\n",
    "| `facebook/bart-large-mnli` | Hugging Face | Classification | ‚úÖ | No training needed, high accuracy | Large (~1.6GB), slower on CPU |\n",
    "| `typeform/distilbert-base-uncased-mnli` | Hugging Face | Classification | ‚úÖ | Fast, smaller, great for CPU | Slightly lower accuracy |\n",
    "| `MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli` | Hugging Face | Classification | ‚úÖ | Multilingual, zero-shot | Medium size |\n",
    "| `joeddav/xlm-roberta-large-xnli` | Hugging Face | Classification | ‚úÖ | Multilingual | Tokenizer issues unless patched |\n",
    "| **Azure AI Language (Text Classification)** | Azure | Classification | üü° Free Tier + Paid | No infra needed, scalable | Requires Azure setup |\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Embedding + ML Classifier (Train Your Own)\n",
    "\n",
    "| Model Name | Source | Tasks | Free? | Pros | Cons |\n",
    "|------------|--------|-------|-------|------|------|\n",
    "| `sentence-transformers/all-MiniLM-L6-v2` | Hugging Face | Embedding + Classifier | ‚úÖ | Fast, tiny, great for CPU | Needs labeled data |\n",
    "| `sentence-transformers/paraphrase-MiniLM-L6-v2` | Hugging Face | Embedding + Classifier | ‚úÖ | Optimized for intent | Needs training |\n",
    "| `BAAI/bge-small-en-v1.5` | Hugging Face | Embedding + Classifier | ‚úÖ | Excellent at intent matching | Needs classifier |\n",
    "| `bert-base-uncased` | Hugging Face | Embedding/Fine-tuning | ‚úÖ | Canonical BERT model | Slower, larger |\n",
    "| **Azure ML Custom Text Classification** | Azure | Trainable classifier | üü° Free + Paid | No model management needed | Requires config, training data |\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Instruction-Following LLMs (Prompt-Based Classification & Extraction)\n",
    "\n",
    "| Model Name | Source | Tasks | Free? | Pros | Cons |\n",
    "|------------|--------|-------|-------|------|------|\n",
    "| `google/flan-t5-base` | Hugging Face | Classification + Extraction | ‚úÖ | Small, CPU-friendly | Prompt-sensitive |\n",
    "| `HuggingFaceH4/zephyr-7b-alpha` | Hugging Face | Classification + Extraction | ‚úÖ | Accurate, prompt-aware | Needs GPU |\n",
    "| `tiiuae/falcon-7b-instruct` | Hugging Face | Same | ‚úÖ | Open-source, LLM-class | Heavy |\n",
    "| `mistralai/Mistral-7B-Instruct-v0.1` | Hugging Face | Same | ‚úÖ (gated) | Strong instruction model | Needs GPU + access |\n",
    "| **Claude 3 (Opus/Sonnet/Haiku)** | Anthropic | Both | ‚ùå Paid | Safe, very accurate | API access only |\n",
    "| **Gemini Pro 1.5** | Google | Both | ‚ùå Paid | Smart, handles complex prompts | Vertex AI setup |\n",
    "| **GPT-3.5 / GPT-4** | OpenAI | Both | ‚ùå Paid | Reliable, fast JSON parsing | API cost, usage limits |\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Information Extraction-Specific Tools\n",
    "\n",
    "| Tool / Model | Source | Tasks | Free? | Pros | Cons |\n",
    "|--------------|--------|-------|-------|------|------|\n",
    "| `spaCy` + NER | Open-source | Extraction | ‚úÖ | Fast, local, trainable | Needs domain tuning |\n",
    "| `dslim/bert-base-NER` | Hugging Face | Extraction | ‚úÖ | Plug-and-play, supports entities | Generic types |\n",
    "| **Azure AI Document Intelligence** | Azure | Extraction | üü° Free Tier + Paid | Structured & unstructured data | Setup required |\n",
    "| **Google Doc AI** | Google | Extraction | ‚ùå Paid | Invoice, receipt extraction | Cloud-only |\n",
    "| **LLMs via Prompting** | GPT, Claude, Flan | Extraction via prompt | ‚ùå Usually Paid | Very flexible | Prompt engineering needed |\n",
    "\n",
    "---\n",
    "\n",
    "### üß© Suggested Stack by Use Case\n",
    "\n",
    "| Goal | Recommended Stack |\n",
    "|------|--------------------|\n",
    "| üî• Fast, no training | `facebook/bart-large-mnli` or `flan-t5-base` |\n",
    "| üõ†Ô∏è Custom training | `MiniLM` + `LogisticRegression` |\n",
    "| üåç Multilingual | `DeBERTa`, `joeddav/xlm-roberta`, Azure |\n",
    "| üß† Smartest output | `Claude` / `GPT-4` / `Gemini` |\n",
    "| üí¨ Text + info extraction | LLM prompt-based (`Flan`, `Claude`) |\n",
    "| üßæ Business docs | `Azure Document Intelligence` or `Google Doc AI` |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Choose whether you're targeting **free/open-source**, **cloud APIs**, or **hybrid**.\n",
    "2. Start with a classifier (`zero-shot` or `MiniLM`) for intent detection.\n",
    "3. Add an extractor module later for structured fields like address, items, etc.\n",
    "4. Optionally, build a wrapper pipeline or API to combine both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üü© Zero-Shot Models (no examples needed)\n",
    "- facebook/bart-large-mnli\n",
    "- DeBERTa-v3-mnli\n",
    "- distilbert-base-mnli\n",
    "\n",
    "üü¶ Few-Shot Models (examples in prompt)\n",
    "- Flan-T5\n",
    "- Zephyr, Mistral\n",
    "- GPT-4, Claude, Gemini\n",
    "\n",
    "üüß Fine-Tuned Models (train your own or hosted)\n",
    "- MiniLM + LogisticRegression\n",
    "- Azure AI Language\n",
    "- Vertex AI fine-tuning\n",
    "- spaCy NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the zero-shot classifier\n",
    "# classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "models = {\"bart\": \"facebook/bart-large-mnli\",\n",
    "         \"distilBERT\":\"typeform/distilbert-base-uncased-mnli\",\n",
    "        \n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=models['bart'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long labels for improved performance of the model \n",
    "label_map = {\n",
    "    \"The user wants to place a new order\": \"new_order\",\n",
    "    \"The user is asking about the status of an order\": \"order_status\",\n",
    "    \"The message is a general question about products or services\": \"general_inquiry\",\n",
    "    \"The user is unhappy and is filing a complaint\": \"complaint\",\n",
    "    \"The user wants to return or get a refund\": \"return_refund\",\n",
    "    \"The user is following up on a previous conversation\": \"follow_up\",\n",
    "    \"The user is giving feedback, suggestions, or compliments\": \"feedback\",\n",
    "    \"The message doesn‚Äôt fit any category above\": \"others\"\n",
    "}\n",
    "\n",
    "# Tried to make it more informative but it lowerd down the score as well as the predcution was wrong\n",
    "# label_map = {\n",
    "#     \"The customer wants to place a new order or buy something\": \"new_order\",\n",
    "#     \"The customer is asking about the delivery or status of an order\": \"order_status\",\n",
    "#     \"The customer is asking a general question about products, policies, or services\": \"general_inquiry\",\n",
    "#     \"The customer is unhappy or expressing dissatisfaction\": \"complaint\",\n",
    "#     \"The customer wants to return a product or request a refund\": \"return_refund\",\n",
    "#     \"The customer is following up on a previous message or request\": \"follow_up\",\n",
    "#     \"The customer is providing feedback, suggestions, or compliments\": \"feedback\",\n",
    "#     \"The message does not clearly match any of the categories above\": \"others\"\n",
    "# }\n",
    "\n",
    "long_labels = list(label_map.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_message(text, long_labels, label_map, threshold=0.6):\n",
    "    \n",
    "#     The wrapped texts are another way of improving the performance but didn't work here. lower score\n",
    "#     wrapped_text = f\"Classify this customer support message: '{text}'\"\n",
    "#     result = classifier(wrapped_text, long_labels)\n",
    "    \n",
    "    result = classifier(text, long_labels)\n",
    "    \n",
    "    top_long_label = result[\"labels\"][0]\n",
    "    top_score = result[\"scores\"][0]\n",
    "    predicted_short_label = label_map[top_long_label]\n",
    "\n",
    "    print(f\"\\nüìù Message: {text}\")\n",
    "    print(f\"üè∑Ô∏è Predicted: {predicted_short_label} (Confidence: {top_score:.2f})\")\n",
    "\n",
    "    if top_score < threshold:\n",
    "        print(\"‚ö†Ô∏è Confidence below threshold. Consider fallback or human review.\")\n",
    "\n",
    "    print(\"\\nüîç All scores:\")\n",
    "    for long_label, score in zip(result[\"labels\"], result[\"scores\"]):\n",
    "        short = label_map[long_label]\n",
    "        print(f\"{short}: {score:.2f}\")\n",
    "\n",
    "    return predicted_short_label, top_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Message: Can I return just one item from the bundle?\n",
      "üè∑Ô∏è Predicted: return_refund (Confidence: 0.45)\n",
      "‚ö†Ô∏è Confidence below threshold. Consider fallback or human review.\n",
      "\n",
      "üîç All scores:\n",
      "return_refund: 0.45\n",
      "general_inquiry: 0.20\n",
      "feedback: 0.13\n",
      "follow_up: 0.11\n",
      "order_status: 0.05\n",
      "new_order: 0.03\n",
      "complaint: 0.02\n",
      "others: 0.01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('return_refund', 0.45484107732772827)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test a message\n",
    "text = \"Can I return just one item from the bundle?\"\n",
    "classify_message(text, long_labels, label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Message: Can I return the yoga mat I ordered last week?\n",
      "üè∑Ô∏è Predicted: return_refund (Confidence: 0.40)\n",
      "‚ö†Ô∏è Confidence below threshold. Consider fallback or human review.\n",
      "\n",
      "üîç All scores:\n",
      "return_refund: 0.40\n",
      "order_status: 0.25\n",
      "general_inquiry: 0.15\n",
      "follow_up: 0.12\n",
      "feedback: 0.05\n",
      "complaint: 0.03\n",
      "new_order: 0.01\n",
      "others: 0.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('return_refund', 0.3982800543308258)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Can I return the yoga mat I ordered last week?\"\n",
    "classify_message(text, long_labels, label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third attempt using a multi_label_map\n",
    "multi_label_map = {\n",
    "    \"new_order\": [\n",
    "        \"The customer wants to place a new order\",\n",
    "        \"The message shows intent to purchase something\",\n",
    "        \"The user is ready to buy a product\"\n",
    "    ],\n",
    "    \"order_status\": [\n",
    "        \"The customer is asking about the status of an order\",\n",
    "        \"The user wants to know where their order is\",\n",
    "        \"The message is about tracking or delivery progress\"\n",
    "    ],\n",
    "    \"general_inquiry\": [\n",
    "        \"The customer is asking a general question about products or services\",\n",
    "        \"The message is a product or service inquiry\",\n",
    "        \"The user is requesting information about offerings or policies or brochures\"\n",
    "    ],\n",
    "    \"complaint\": [\n",
    "        \"The customer is expressing dissatisfaction with a product or service\",\n",
    "        \"The user is reporting a problem or issue\",\n",
    "        \"The message contains a complaint or negative experience\"\n",
    "    ],\n",
    "    \"return_refund\": [\n",
    "        \"The customer wants to return a product\",\n",
    "        \"The user is requesting a refund\",\n",
    "        \"The message is about returning or exchanging an item\"\n",
    "    ],\n",
    "    \"follow_up\": [\n",
    "        \"The customer is following up on a previous message\",\n",
    "        \"The user is checking the status of a prior conversation\",\n",
    "        \"The message is a reminder or nudge for a response\"\n",
    "    ],\n",
    "    \"feedback\": [\n",
    "        \"The customer is giving feedback or a suggestion\",\n",
    "        \"The user is leaving a compliment or review\",\n",
    "        \"The message shares an opinion or appreciation\"\n",
    "    ],\n",
    "    \"others\": [\n",
    "        \"The message does not fit any specific category\",\n",
    "        \"This is a generic message with no clear intent\",\n",
    "        \"The content is irrelevant or not related to customer service\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_with_flat_hypotheses(text, multi_label_map, threshold=0.15):\n",
    "    all_phrases = []\n",
    "    phrase_to_label = {}\n",
    "\n",
    "    # 1. Flatten all hypotheses and track their label\n",
    "    for label, phrases in multi_label_map.items():\n",
    "        for phrase in phrases:\n",
    "            all_phrases.append(phrase)\n",
    "            phrase_to_label[phrase] = label\n",
    "\n",
    "    # 2. Run once on all hypotheses\n",
    "    result = classifier(text, all_phrases)\n",
    "\n",
    "    # 3. Aggregate raw scores by label\n",
    "    scores_by_label = {}\n",
    "    for phrase, score in zip(result[\"labels\"], result[\"scores\"]):\n",
    "        label = phrase_to_label[phrase]\n",
    "        if label not in scores_by_label:\n",
    "            scores_by_label[label] = []\n",
    "        scores_by_label[label].append(score)\n",
    "\n",
    "    # 4. Average per label\n",
    "    averaged_scores = {\n",
    "        label: sum(scores) / len(scores) for label, scores in scores_by_label.items()\n",
    "    }\n",
    "\n",
    "    # 5. Normalize scores to sum to 1\n",
    "    total_score = sum(averaged_scores.values())\n",
    "    normalized_scores = {\n",
    "        label: score / total_score for label, score in averaged_scores.items()\n",
    "    }\n",
    "\n",
    "    # 6. Pick the top label\n",
    "    sorted_labels = sorted(normalized_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_label, top_score = sorted_labels[0]\n",
    "\n",
    "    # 7. Display results\n",
    "    print(f\"\\nüìù Message: {text}\")\n",
    "    print(f\"üè∑Ô∏è Predicted: {top_label} (Normalized Confidence: {top_score:.2f})\")\n",
    "    if top_score < threshold:\n",
    "        print(\"‚ö†Ô∏è Confidence below threshold. Consider fallback or human review.\")\n",
    "\n",
    "    print(\"\\nüîç Normalized Scores:\")\n",
    "    for label, score in sorted_labels:\n",
    "        print(f\"{label}: {score:.2f}\")\n",
    "\n",
    "    return top_label, top_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Message: Can I return just one item from the bundle?\n",
      "üè∑Ô∏è Predicted: return_refund (Normalized Confidence: 0.34)\n",
      "\n",
      "üîç Normalized Scores:\n",
      "return_refund: 0.34\n",
      "feedback: 0.24\n",
      "complaint: 0.14\n",
      "follow_up: 0.11\n",
      "general_inquiry: 0.08\n",
      "new_order: 0.05\n",
      "order_status: 0.03\n",
      "others: 0.01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('return_refund', 0.3414390419113004)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Can I return just one item from the bundle?\"\n",
    "classify_with_flat_hypotheses(text, multi_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_label_only(text, multi_label_map):\n",
    "    all_phrases = []\n",
    "    phrase_to_label = {}\n",
    "\n",
    "    # Flatten hypotheses and track labels\n",
    "    for label, phrases in multi_label_map.items():\n",
    "        for phrase in phrases:\n",
    "            all_phrases.append(phrase)\n",
    "            phrase_to_label[phrase] = label\n",
    "\n",
    "    # Run zero-shot classification once\n",
    "    result = classifier(text, all_phrases)\n",
    "\n",
    "    # Aggregate scores by label\n",
    "    scores_by_label = {}\n",
    "    for phrase, score in zip(result[\"labels\"], result[\"scores\"]):\n",
    "        label = phrase_to_label[phrase]\n",
    "        if label not in scores_by_label:\n",
    "            scores_by_label[label] = []\n",
    "        scores_by_label[label].append(score)\n",
    "\n",
    "    # Average scores and pick top label\n",
    "    averaged_scores = {\n",
    "        label: sum(scores) / len(scores) for label, scores in scores_by_label.items()\n",
    "    }\n",
    "\n",
    "    top_label = max(averaged_scores, key=averaged_scores.get)\n",
    "    return top_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'return_refund'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Can I return just one item from the bundle?\"\n",
    "classify_label_only(text, multi_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Load the training dataset using relative path\n",
    "with open(\"../data/training.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "messages = data[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1. Text: What are your store hours on weekends?\n",
      "   Actual: general_inquiry | Predicted: general_inquiry\n",
      "\n",
      "  2. Text: Can I get a sample before buying?\n",
      "   Actual: general_inquiry | Predicted: new_order\n",
      "\n",
      "  3. Text: How do I check the delivery status?\n",
      "   Actual: order_status | Predicted: order_status\n",
      "\n",
      "  4. Text: The refund amount is incorrect.\n",
      "   Actual: return_refund | Predicted: complaint\n",
      "\n",
      "  5. Text: Testing integration.\n",
      "   Actual: others | Predicted: feedback\n",
      "\n",
      "  6. Text: Excellent experience overall.\n",
      "   Actual: feedback | Predicted: feedback\n",
      "\n",
      "  7. Text: Need resolution urgently.\n",
      "   Actual: follow_up | Predicted: complaint\n",
      "\n",
      "  8. Text: Your return form isn‚Äôt working.\n",
      "   Actual: return_refund | Predicted: complaint\n",
      "\n",
      "  9. Text: How long does shipping take?\n",
      "   Actual: general_inquiry | Predicted: order_status\n",
      "\n",
      " 10. Text: Can someone please check my previous issue?\n",
      "   Actual: follow_up | Predicted: complaint\n",
      "\n",
      " 11. Text: How can I get a catalog?\n",
      "   Actual: general_inquiry | Predicted: general_inquiry\n",
      "\n",
      " 12. Text: Please cancel my order and issue a refund.\n",
      "   Actual: return_refund | Predicted: complaint\n",
      "\n",
      " 13. Text: No one answers the phone!\n",
      "   Actual: complaint | Predicted: complaint\n",
      "\n",
      " 14. Text: This is very disappointing.\n",
      "   Actual: complaint | Predicted: complaint\n",
      "\n",
      " 15. Text: Great job on the delivery time!\n",
      "   Actual: feedback | Predicted: feedback\n",
      "\n",
      " 16. Text: Your delivery service is too slow.\n",
      "   Actual: complaint | Predicted: complaint\n",
      "\n",
      " 17. Text: Is your hand cream suitable for sensitive skin?\n",
      "   Actual: general_inquiry | Predicted: general_inquiry\n",
      "\n",
      " 18. Text: Where are you located?\n",
      "   Actual: general_inquiry | Predicted: feedback\n",
      "\n",
      " 19. Text: Poor response time!\n",
      "   Actual: complaint | Predicted: complaint\n",
      "\n",
      " 20. Text: Can I order through WhatsApp directly?\n",
      "   Actual: new_order | Predicted: new_order\n",
      "\n",
      " 21. Text: ‚Ä¶\n",
      "   Actual: others | Predicted: feedback\n",
      "\n",
      " 22. Text: Why hasn't my package moved in 3 days?\n",
      "   Actual: order_status | Predicted: complaint\n",
      "\n",
      " 23. Text: Random message\n",
      "   Actual: others | Predicted: others\n",
      "\n",
      " 24. Text: Ping!\n",
      "   Actual: others | Predicted: feedback\n",
      "\n",
      " 25. Text: Is gift wrapping available?\n",
      "   Actual: general_inquiry | Predicted: general_inquiry\n",
      "\n",
      " 26. Text: I‚Äôd like to return my order.\n",
      "   Actual: return_refund | Predicted: complaint\n",
      "\n",
      " 27. Text: The handwritten note was a nice touch.\n",
      "   Actual: feedback | Predicted: feedback\n",
      "\n",
      " 28. Text: When can I expect delivery?\n",
      "   Actual: order_status | Predicted: order_status\n",
      "\n",
      " 29. Text: Just following up on my last message.\n",
      "   Actual: follow_up | Predicted: follow_up\n",
      "\n",
      " 30. Text: asdfghjkl\n",
      "   Actual: others | Predicted: feedback\n",
      "\n",
      "\n",
      " Accuracy: 53.33% (16/30)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "results=[]\n",
    "correct=0\n",
    "selected_messages =30\n",
    "for i, msg in enumerate(random.sample(messages, selected_messages), start=1):\n",
    "    text = msg[\"message\"]\n",
    "    actual = msg[\"category\"]\n",
    "    \n",
    "    response = classify_label_only(text, multi_label_map)\n",
    "    predicted = response.strip()\n",
    "    results.append({\n",
    "    \"message\": text,\n",
    "    \"actual\": actual,\n",
    "    \"predicted\": predicted\n",
    "    })\n",
    "    if predicted == actual:\n",
    "        correct += 1\n",
    "\n",
    "    print(f\"{i:>3}. Text: {text}\")\n",
    "    print(f\"   Actual: {actual} | Predicted: {predicted}\\n\")\n",
    "    \n",
    "accuracy = correct / selected_messages\n",
    "print(f\"\\n Accuracy: {accuracy:.2%} ({correct}/{selected_messages})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
